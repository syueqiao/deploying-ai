{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cd4e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.newyorker.com/magazine/2024/04/22/what-is-noise', 'title': 'What Is Noise? | The New Yorker', 'description': 'Sometimes we embrace it, sometimes we hate it—and everything depends on who is making it, Alex Ross writes.', 'language': 'en-US'}, page_content='What Is Noise? | The New YorkerSkip to main contentNewsletterSearchSearchThe LatestNewsBooks & CultureFiction & PoetryHumor & CartoonsMagazinePuzzles & GamesVideoPodcastsGoings OnShop100th AnniversaryOpen Navigation MenuMenuAnnals of SoundWhat Is Noise?Sometimes we embrace it, sometimes we hate it—and everything depends on who is making it.By Alex RossApril 15, 2024Noise has come to mean an engulfing barrage of data—less an event than a condition.Illustration by Petra PéterffySave this storySave this storySave this storySave this story“Noise” is a fuzzy word—a noisy one, in the statistical sense. Its meanings run the gamut from the negative to the positive, from the overpowering to the mysterious, from anarchy to sublimity. The negative seems to lie at the root: etymologists trace the word to “nuisance” and “nausea.” Noise is what drives us mad; it sends the Grinch over the edge at Christmastime. (“Oh, the Noise! Noise! Noise! Noise!”) Noise is the sound of madness itself, the din within our minds. The demented narrator of Poe’s “The Tell-Tale Heart” jabbers about noise while he hallucinates his victim’s heartbeat: “I found that the noise was not within my ears.\\xa0.\\xa0.\\xa0. The noise steadily increased.\\xa0.\\xa0.\\xa0. The noise steadily increased.”Yet noise can be righteous and majestic. The Psalms are full of joyful noise, noise unto the Lord. In the Book of Ezekiel, the voice of God is said to be “like a noise of many waters.” In “Paradise Lost,” Heaven makes “infernal noise” as it beats back the armies of Hell. Public Enemy’s “Bring the Noise” marshals forces for a different kind of battle. At the same time, the word can summon all manner of gentler murmurs: “The isle is full of noises,\\xa0/\\xa0Sounds and sweet airs.” Tennyson speaks of a “noise of hymns,” Coleridge of a “noise like of a hidden brook.” In Elizabethan England, a “noyse” could be a musical ensemble, such as the one that supplied a “heavenly melodie” for Queen Elizabeth I’s coronation pageant. Any hope of limiting the scope of the term evaporated when information theorists detached it from acoustics altogether and applied it to any ambient activity that hinders a signal. Noise has come to mean an engulfing barrage of data—less an event than a condition.Other languages handle noise a bit less vaguely. In French, the most common term is bruit, which comes from the Latin for “roar.” That’s a straightforward description of what a noise sounds like, as opposed to a subjective assessment of how it might upset us. In German, Lärm tends to indicate louder noises, Geräusch softer, more natural ones. Russians have a range of words, including shum, which, according to Vladimir Nabokov, suggests “more of a swoosh than a racket.” When Osip Mandelstam wrote of shum vremeni—“the noise of time”—he captured an essential texture of modern life.Noise is capacious enough to have inspired a small and ever-growing library. Alongside various cultural histories—Bart Kosko’s “Noise,” David Hendy’s “Noise,” Mike Goldsmith’s “Discord: The Story of Noise,” Hillel Schwartz’s nine-hundred-page “Making Noise”—you can read accounts of noise-music scenes (“Japanoise,” “New York Noise”), noise-based literary criticism (“Shakespeare’s Noise,” “Kafka and Noise”), and philosophies of noise (“An Epistemology of Noise,” “Noise Matters: Toward an Ontology of Noise”), not to mention practical-minded guides to reducing noise from your hvac unit or reducing the noise in your head. How noise relates to music is a much bruited topic in itself. Samuel Johnson offers an elegant resolution: “Of all noises, I think music the least disagreeable.” Music is our name for the noise that we like.With a universal definition hovering out of reach, the discourse concerning noise often starts with the personal. My history with the thing is fraught: I hate it and I love it. As a child, I was extraordinarily sensitive to loud sounds. Family expeditions to Fourth of July fireworks displays or steam-railway museums routinely ended with me running in tears to the safety of the car. When, in early adulthood, I moved into the noise cauldron of New York City, I was tormented by neighbors’ stereos and by the rumble of the street. I stuffed windows with pillows and insulation; I invested in industrial-strength earplugs; I positioned an oversized window fan next to my bed. This neurosis has subsided, but I remain that maddening hotel guest who switches rooms until he finds one that overlooks an airshaft or an empty lot.All the while, I was drawn to music that others would pay money to avoid. Having grown up with classical music, I found my way to the refined bedlam of the twentieth-century avant-garde: Edgard Varèse, John Cage, Karlheinz Stockhausen, György Ligeti. In college, I hosted a widely unheard radio show on which I broadcast things like Ligeti’s “Poème Symphonique”—a piece for a hundred metronomes. When someone called in to report that the station’s signal had gone down, I protested that we were, in fact, listening to music. Similar misunderstandings arose when I aired Cage’s “Imaginary Landscape No. 4,” for twelve radios. When I moved on to so-called popular music, I had ears only for the churning dissonances of Cecil Taylor, AMM, and Sonic Youth. I became the keyboardist in a noise band, which made one proudly chaotic public appearance, in 1991. At one point, my bandmates and I improvised over a tape loop of the minatory opening chords of Richard Strauss’s “Die Frau Ohne Schatten.”Obviously, my issues with noise pivot on the question of control. When the noise occurs on my own terms, I enjoy it; when it’s imposed on me, I recoil. This bifurcation is typical, even if I represent an extreme case. Garret Keizer, in his incisive 2010 book, “The Unwanted Sound of Everything We Want: A Book About Noise,” observes that the noise/music distinction is ultimately an ethical one. If you elect to hear something, it is not noise, even if most people might deem it unspeakably horrible. If you are forced to hear something, it is noise, even if most people might deem it ineffably gorgeous. Thus, Keizer writes, “Lou Reed’s ‘Metal Machine Music’ performed at the Gramercy is not noise; Gregorian Chant piercing my bathroom wall is.”“Unwanted sound” is the basic definition. An act of aggression is implied: someone is exercising power by projecting sound into your space. Sometimes the act is unconscious: people don’t realize how loud their speakers are, or they assume that everyone loves their music as much as they do. Sometimes, though, it is a gesture of undisguised brutality. Late one night in 2002, I asked some frat-boyish neighbors to turn down their thumping techno. They responded by turning it up. When I complained again, one of them began shouting “Fucking faggot!” and hurling his body against my door. I lacked the presence of mind to remark upon the irony of homophobes blasting techno—in Chelsea, of all places.We seldom reject the sounds of people we like. Disputes over noise expose social fissures. The classic cinematic study of music, noise, and violence is Spike Lee’s “Do the Right Thing,” in which Radio Raheem brings his boom box inside Sal’s pizzeria, blaring Public Enemy’s “Fight the Power.” Sal says, “What did I tell you about that noise?” Radio Raheem protests, “This is music. My music.” Minutes later, he is dead, the victim of a police killing.“I bring you I.P.”Cartoon by Jason Adam Katzenstein and Eliza HittmanCopy link to cartoonCopy link to cartoonLink copiedShopShopThe perception of hip-hop as “Black Noise”—the title of a 1994 book by the pop-culture scholar Tricia Rose—is part of a long history of sonic dehumanization directed at minority groups. The word “barbarian” originates from a disparaging Greek term, bárbaros, which appears to evoke the alleged gibberish of foreign peoples (“bar bar bar”). The musicologist Ruth HaCohen has tracked long-standing European perceptions of Jews as a peculiarly noisy people. “Lärm wie in einer Judenschule,” or “noise as in a synagogue,” remained a popular German expression into the Nazi period. (Mandelstam inverts those perceptions in “The Noise of Time,” relishing the intricacy of “Jewish chaos.”) Colonizers who disdained the weird sounds of native peoples overlooked the fact that they themselves were causing unprecedented levels of commotion—bells, trumpets, guns, cannons, machines. Noise enables power. As Keizer writes, it is a way of saying, “The world is mine.”Amid the hubbub of urban life, silence is a luxury of the rich. They can afford the full-floor penthouse apartment, the house that sits on a quiet acre. They can install triple-paned windows and pump insulation into the walls. They can, if they choose, become Proust in his cork-lined room. For the rest of society, noise is an index of struggle. Hendy’s “Noise,” which is based on a 2013 BBC Radio series, documents the ruckus of tenement living in eighteenth-century Edinburgh and the altogether hellish clamor inflicted on ironworkers in nineteenth-century Glasgow. A doctor wrote of a group of Glasgow boilermakers, “The iron on which they stand is vibrating intensely under the blows of perhaps twenty hammers wielded by twenty powerful men. Confined by the walls of the boiler, the waves of sound are vastly intensified, and strike the tympanum with appalling force.”The colossal cacophony of the Industrial Revolution prompted some of the first serious efforts at noise control. Often, these amounted to crabby élitism. Charles Babbage lamented the “organ-grinders and other similar nuisances” who were degrading the productivity of “intellectual workers.” Charles Dickens signed a letter claiming that writers and artists had become “especial objects of persecution by brazen performers on brazen instruments.” But the New York anti-noise activist Julia Barnett Rice, who founded the Society for the Suppression of Unnecessary Noise in 1906, transcended upper-crust narcissism by arguing that people of all backgrounds were suffering from excessive noise in schools and hospitals. She intuited what scientific studies later confirmed—that noise can inhibit learning and complicate health issues. It can also, of course, cause auditory damage, in the form of tinnitus, and hearing loss.Attempts to mitigate and legislate noise levels run up against the challenge of adjudicating which sounds are excessive and unpleasant. Measuring loudness is itself a tricky business. The decibel scale, like the Richter scale, is logarithmic, and it accounts for quirky neural responses to changing stimuli. A twenty-decibel sound is generally perceived as being twice as loud as a ten-decibel one, yet the actual intensity is ten times greater. Furthermore, the decibel scale is customarily weighted to factor in additional peculiarities. We are more sensitive to upper frequencies (a soprano is more conspicuous than a bass), to indoor sounds, to nighttime sounds. With all these complexities, noise codes, where they exist, are difficult to enforce. In 2022, New York City’s Department of Environmental Protection received nearly fifty thousand complaints but imposed monetary penalties in only a hundred and twenty-three instances.Emergency warnings—foghorns, locomotive whistles, ambulance and fire-truck sirens, air-raid sirens—fall into a special category of necessary, life-saving noise. Car horns are a borderline case: sometimes they stave off disaster, but more often they foster road rage. Matthew F. Jordan’s “Danger Sound Klaxon!: The Horn That Changed History” studies one of the most purposefully obnoxious noises of modern times—the “aa-ooo-gah!” honk that became ubiquitous on American roads in the early twentieth century. In a free-for-all traffic environment, drivers alerted pedestrians and other vehicle operators by using the horn incessantly. Ads for the Klaxon—invented by the electrical engineer Miller Reese Hutchison, and introduced in 1907—boasted of its ability to “cut through and kill musical sounds.” Raw panic was the aim. During the First World War, the Klaxon was used to warn of gas attacks; it then declined in popularity, partly because traumatized veterans reacted poorly to its squawk.We humans have a high tolerance for noise, despite our ambivalence. In some way, we seem to require it. Other species feel differently about the never-ending sonic havoc of the Anthropocene. Caspar Henderson, in “A Book of Noises: Notes on the Auraculous,” points out that when our species stayed mostly indoors during the early months of the covid pandemic the animal world reacted with apparent relief: “Birdsongs regained qualities that had last been recorded decades before, when cities were quieter. The white-crowned sparrows, for instance, extended their sounds back down into lower frequencies\\xa0.\\xa0.\\xa0. and their songs became richer, fuller and more complex.” Birds also sang more softly: they “had been ‘shouting,’ just as people raise their voices on a construction site or at a noisy party.” Their stress levels likely declined. Noise is another dimension of humanity’s ruination of the natural world.The inexorable advance of technological noise in the twentieth century—cars, airplanes, helicopters, pile drivers, lawnmowers, leaf blowers, home stereos, stadium sound systems—left the impression that the world was getting louder year by year. This may well have been so, but in recent decades there has actually been a levelling off, or even a decline, in certain types of noise. Jet engines are less thunderous than they were in the seventies. The increasing popularity of electric vehicles has brought about a situation in which cars can be dangerously inaudible to pedestrians. (Artificial engine noise has become a feature of electric models.) People now routinely listen to music on laptops and headphones, reducing incursions of bass.These modest gains are offset by the rise of informational noise, which further blurs the meaning of the already confused parent word. Chen-Pang Yeang’s “Transforming Noise: A History of Its Science and Technology from Disturbing Sounds to Informational Errors, 1900-1955” is thick with mathematical equations, yet it still tells an interesting story even for those of us who will skip the more technical pages. Beneath the vehicular roar in the years around 1900 was a simmering new electronic sound, native to the telephone, the phonograph, the radio, and other forms of transmission and reproduction. Yeang describes this noise as “disturbances and fluctuations of electrical current due to the movements of microscopic charge carriers in electronic tubes and other circuit components.” Such sounds weren’t aggressively unpleasant, yet they hampered the communication of messages, verbal or musical. Scientists and engineers set about studying this electronic sizzle and figuring out how to reduce it.The investigation soon intersected with ongoing inquiries into the movement of gas and liquid particles. Einstein’s papers on Brownian motion, between 1905 and 1908, not only established the existence of atoms; they also helped to systematize the discipline of statistical mechanics, which describes patterns of random fluctuations over time, also known as stochastic processes. Defense work during the Second World War adapted those insights to military ends: devising uncrackable cryptography, resisting signal jamming, reducing interference in anti-aircraft radar systems. Claude Shannon, the founder of information theory, took an even more significant step by demonstrating how a signal can cope with a “noisy” channel—literally or figuratively—if it behaves in a noisy, stochastic way: by spreading itself across a broad spectrum, it transmits more effectively. That insight underpins modern cellular and wireless communications. It was a curious extension of the logic of the Klaxon: in a world full of noise, you punch through by making noise at a superior level.Soon enough, the concept of stochastic noise, often simplified to the point of vanishing, achieved currency in a dizzying array of fields. Noise studies of recent decades examine perturbations in the stock market (the economist Fischer Black’s paper “Noise”), unreliable patterns in decision-making (Daniel Kahneman, Olivier Sibony, and Cass Sunstein’s “Noise: A Flaw in Human Judgment”), and irregularities in political polling (Nate Silver’s “The Signal and the Noise”). The proposed corrective for such errancy is, very often, the dreaded algorithm. Kahneman and company argued that algorithms, being “noise-free,” can “outperform human judgment.” Machine-learning protocols in artificial intelligence, meanwhile, rely heavily on stochastic processes. The ultimate import of much of this work is that humans are themselves randomly fluctuating particles whose behavior, in aggregate, can be forecast by probabilistic methods.Yeang helps out the mathematically illiterate by offering a literary frame for noise’s semantic shift. In his introduction, he juxtaposes a nineteenth-century account of invasive sound—Nathaniel Hawthorne’s dismayed reaction to a train whistle—with the Reagan-era data-scape of Don DeLillo’s “White Noise,” with its swarm of “words, pictures, numbers, facts, graphics, statistics, specks, waves, particles, motes.” White noise is a sound field in which all frequencies are equally intense. When the married couple at the novel’s center, Babette and Jack, have a conversation about death, the crack of doom becomes a wash of static:“What if death is nothing but sound?”“Electrical noise.”“You hear it forever. Sound all around. How awful.”“Uniform, white.”White noise is the master noise in which all other noises drown. The perpetual swirl of cultural particles mutes the resonance of any individual voice. The irony is that the atomized buzz common to so much late-twentieth-century technology—fax machines, dial-up modems, the hiss between stations on a radio dial, the “Poltergeist” snow of a TV left on overnight—has largely faded. Such noise now resides in our minds, as we fend off notifications, updates, “Just for You” suggestions, consumer-feedback requests, obscene spam, clickbait headlines, A.I.-generated news stories, A.I.-generated news stories about A.I., and the whole silently screaming rest of it.From time to time, nature unleashes a noise so immense that it restores the Biblical grandeur of the word. Many books on noise mention the Indonesian volcano Krakatoa, which, in August, 1883, disgorged what is commonly called the loudest sound in modern history. The eruption was audible from as far as three thousand miles away. The captain of a British ship that was forty miles distant wrote, “So violent are the explosions that the eardrums of over half my crew have been shattered. My last thoughts are with my dear wife. I am convinced that the Day of Judgment has come.”In October, I went to the Brooklyn experimental-music venue ISSUE Project Room to hear “VirtuAural Electro-Mechanics,” a fifty-minute-long audio collage by the sound artist Francisco López. The performance space—a cavernous Beaux-Arts gallery that McKim, Mead & White had originally designed for the Elks organization—was plunged into darkness. Attendees were given masks to cover their eyes. In a program note, López writes, “This creation was developed from a myriad of original sound recordings of mechanical machines, electro-mechanical systems and industrial environments gathered over the past 25 years all over the world; from food factories to ‘white rooms,’ from 18th-century automata to computers, from wood and wires to magnetism, from the microscopic to the monumental.”If you demand that music provide an oasis of melodious sweetness, “VirtuAural Electro-Mechanics” would not be for you. It is an experience of overwhelming density. Loudness is not its chief characteristic—any average rock show or dance club would outdo it in decibels—but it covers such a vast range of frequencies and timbres, from lung-shaking bass tones to a tintinnabulation in stratospheric registers, that the brain struggles to assimilate the entirety of it. I imagined phantom structures in the air: the sound was bleeding into my other senses.Is “VirtuAural Electro-Mechanics” music? In the usual sense, no. The Oxford English Dictionary associates music with “beauty of form, harmony, melody, rhythm, expressive content, etc.,” implicitly excluding machines in food factories. The great German physicist Hermann von Helmholtz, in his 1863 tome, “On the Sensations of Tone,” frames music as the opposite of noise. A musical tone, Helmholtz writes, is a “perfectly undisturbed, uniform sound.” Noise is a jumble of rapid, irregular signals. Certain combinations of tones are more pleasing than others, on account of physiological principles that Helmholtz charts in extraordinary detail. European composers have perfected the art of harmony—creating, it would appear, a bulwark against noise.In this same period, though, composers began to have different ideas. Like birds, they were listening to the world around them and mimicking its increasingly raucous character. In Wagner’s “Das Rheingold,” the subterranean smithy of the Nibelungs is evoked by a percussion section that includes, according to the score, eighteen anvils. For a few bars, the orchestra stops playing and the anvils hammer away on their own—industry incarnate. Harmony, meanwhile, was drifting from its tonal moorings: fearsome dissonances in the music of Mahler, Strauss, and Scriabin suggested both the outer density of modern life and the inner turmoil of the individual. Mahler said, “If we want thousands to hear us in the huge auditoriums of our concert halls and opera houses, we simply have to make a lot of noise [Lärm].”Matters came to a head in 1913. The brutish chords that stomp through the second section of Stravinsky’s “Rite of Spring” pack seven of the twelve notes of the Western chromatic scale into a confined space: as a result, pitch becomes a blur. T. S. Eliot later wrote that the “Rite” seems to “transform the rhythm of the steppes into the scream of the motor horn, the rattle of machinery, the grind of wheels, the beating of iron and steel, the roar of the underground railway\\xa0.\\xa0.\\xa0. to transform these despairing noises into music.” On March 31, 1913, two months before the première of the “Rite,” a concert in Vienna featuring works by Arnold Schoenberg and his circle let loose an even more disturbing sound. In Alban Berg’s orchestral song “Über die Grenzen des All,” or “Beyond the Limits of the Universe,” the winds and the brass intone a soft, unearthly sonority in which all twelve pitches are heard. This is an instrumental approximation of white noise, long before the term had been coined. The concert promptly devolved into a riot, one that even the famous uproar around the “Rite” could not equal. Fisticuffs broke out, the police were called, and a lawsuit ensued.Cartoon by Harry Bliss and Steve MartinCopy link to cartoonCopy link to cartoonLink copiedShopShopIn that same year of discord and scandal, the Futurist painter Luigi Russolo published a manifesto titled “L’Arte dei Rumori” (“The Art of Noises”), in which he wrote, “For years, Beethoven and Wagner have deliciously shaken our hearts. Now we are fed up with them. This is why we get infinitely more pleasure imagining combinations of the sounds of trolleys, autos and other vehicles, and loud crowds.” To that end, Russolo and his brother Antonio devised a battery of homemade noise instruments. A recording from 1921 suggests a café band tootling away in a room with bad plumbing. Other composers made more persuasive ventures: solo-percussion works by Amadeo Roldán and by Edgard Varèse, early electronic experiments by Paul Hindemith and by Oskar Sala, noise collages by the young John Cage. Varèse’s mammoth orchestral piece “Amériques,” which descended on Carnegie Hall in 1926, conjures the full pandemonium of the metropolis, with a New York Fire Department siren filling out the orchestra. George Antheil, in his “Ballet Mécanique,” which arrived at Carnegie the following year, called for airplane propellers whirring onstage, though he had to settle for electric fans.As Yeang notes in “Transforming Noise,” Antheil played a cameo role in the evolution of stochastic research. During the Second World War, he assisted the Hollywood star Hedy Lamarr, an Austrian émigré with a mathematical gift, in designing a frequency-hopping technology that would have prevented the jamming of torpedo-guidance systems. Nothing immediately came of the Lamarr-Antheil scheme, though it forecast later breakthroughs. After the war, the engineer turned composer Iannis Xenakis transformed stochastic process into musical language. The instrumental lines of his 1955-56 score “Pithoprakta” are explicitly modelled on Brownian motion. Ligeti’s “Poème Symphonique,” from 1962, does something analogous. At first, the hundred metronomes generate a uniform cloud of indistinguishable ticktocks. Then, as one device after another winds down, the remaining voices become audible. In performance, the “Poème” begins as a comedy and ends as a tragedy—an emblem of a dying ecosystem.Noise enriched popular music, too. Jazz musicians, extending the blues tradition, activated pitches outside the standard twelve-note gamut. The sirenlike sneer of the trombone glissando became a signature sound. Jazz not only cut through the crackle of surface noise but also thrived on it. The emergence of a full-blown jazz avant-garde, after the Second World War, brought musical modernism to an exuberant peak. Rock entered its noise-art phase in the seventies and eighties, with the industrial grind of such bands as Throbbing Gristle and Einstürzende Neubauten. Hip-hop manipulated noise from the outset. Hank Shocklee, Public Enemy’s master producer, echoed the rhetoric of Varèse and Cage when he said, “We believed that music is nothing but organized noise. You can take anything—street sounds, us talking, whatever you want—and make it music by organizing it.\\xa0.\\xa0.\\xa0. This thing you call music is a lot broader than you think it is.”Supreme among noisemakers is Yoko Ono, who first made her name as a principled provocateur in the downtown New York scene—next to her, Cage looked timid—and then shot to global fame through her relationship with John Lennon. Her furiously nuanced screaming of the word “why” at the beginning of “Yoko Ono/Plastic Ono Band,” from 1970, was a masterly act of one-upmanship in the face of the masculinist assault of mainstream rock and roll. Beatles fans, confronted with noise of a higher order, were as aghast as the socialite aristocrats who booed “The Rite of Spring.” Noise is only one part of Ono’s mercurial practice—she is equally drawn to meditative gentleness—but she deserves a central place in histories of the genre. For the most part, she has been left out of them.Implicit in the art of noise is a promise of resistance. For millennia, music has been a medium of control; noise, it follows, is a liberation. Schoenberg went so far as to speak of the “emancipation of the dissonance,” making his harmonic innovations sound like a civil-rights matter. The social theorist Jacques Attali, in his 1977 book, “Noise: The Political Economy of Music,” put a sophisticated spin on that argument. The bruit nouveau that Attali hears emerging from free jazz and the European avant-garde has a revolutionary import: it denies the marketplace, it refuses popular taste, it involves “inventing new codes” and “playing for one’s own pleasure.” Subsequent treatises, such as Paul Hegarty’s “Noise/Music,” have maintained Helmholtz’s duality while reversing its biases, so that noise heroically destroys music’s stifling banalities.The question is: Resistance to what? Nothing about noisemaking guarantees personal or political virtue. Russolo, like many other members of the Futurist movement, found a way to reconcile his bourgeois-bashing ideas with Fascist aesthetics. Varèse was tainted by racism and antisemitism. In more recent decades, Nazi iconography and vocabulary have adorned noise records by Whitehouse and Boyd Rice. The magisterial Japanese noise artist Masami Akita, who has released hundreds of implacably obliterative recordings under the name Merzbow, has shown self-awareness about this mentality of domination. “Sometimes I would like to kill the much too noisy Japanese by my own Noise,” he has said. “The effects of Japanese culture are too much noise everywhere. I want to make silence by my Noise. Maybe that is a fascist way of using sound.”Stephen Graham, who teaches courses on underground music at Goldsmiths, in London, takes a different tack in “Becoming Noise Music,” a survey of the field since the seventies. Aware of the murkiness surrounding the notion of resistance, Graham focusses instead on the genre’s aesthetics. Furthermore, the opposition of “noise” and “music” dissatisfies him: the appeal of this grittiest of genres lies precisely in the erasure of the boundary between the two. There is no way of talking about noise without taking pleasure into account. The pleasure may be confined to a niche audience, and perhaps a somewhat masochistic one, but it exists all the same. No one chooses to listen to a sound because of what it is not.How do you articulate the aesthetics of a music that follows a logic of dumbfounding excess? Graham makes a good stab in some pages devoted to Merzbow’s album “Noisembryo,” from 1994. He begins by observing, somewhat dryly, that the listener is “confronted with a kind of chaotic ‘order’ or musicality flickering into and out of existence as, say, a steady pulse pattern emerges, or an oscillating bass drone throbs into existence, or a panrhythm of clashing noise layers suddenly locks into polyrhythmic place.” He then switches to stream-of-consciousness italics to convey the rush of surrender: “I flow into the beating world, staying there as the music keeps changing and pulsing; it’s possible to transcend—trance—in this way with more conventional music, but the low rate of repetition and high rate of density and strangeness in noise means that such trancing can have a particularly rich tensile quality when it’s achieved.\\xa0.\\xa0.\\xa0. This music takes me out of (my) self and makes me cosmic.”Such effusions are a bit embarrassing to read—but any critic who wishes to capture pleasure must embarrass the reader sooner or later. I experience feelings similar to Graham’s when I lose myself in exemplary spells of musical noise, whether it’s Merzbow, Ono, the apocalyptic war scenes in Chaya Czernowin’s opera “Infinite Now,” or the Krakatoan subwoofer frequencies of Ash Fure’s installation “Hive Rise.” The thrill I get from such sounds doesn’t contradict my abiding love for Bach, Schubert, and Brahms any more than the abstract frenzy of a Jackson Pollock contradicts the radiant calm of a Fra Angelico. What I love about noise is its insistence on otherness, on difference. If music were ever to become a universal language, it would be dead.As for López’s “VirtuAural Electro-Mechanics,” it left me in a state of happy vacancy, as if the digital detritus in my brain had been swept away. Yet I had been engaged in active, alert listening. I’d been nodding and swaying in time, even when no beat was apparent. The colliding pulses seemed to coalesce into a fundamental ghost rhythm that was as insistent as any pounding bass. The mind is its own place, as Milton’s Lucifer says. It can establish its own order, its own harmony. I walked out into the streets of Brooklyn feeling alive, serene, peculiarly free. When I entered the screech of the subway, though, I winced and put on noise-cancelling headphones.\\xa0♦Published in the print edition of the April 22 & 29, 2024, issue.New Yorker FavoritesThe myth of whiteness in classical sculpture.An objectively objectionable grammatical pet peeve.Dorothy Parker’s Profile of Ernest Hemingway.How Maria Callas lost her voice.Adventures in opium.The Reddit forum that guesses who you are based on what’s in your fridge.Sign up for our daily newsletter to receive the best stories from The New Yorker.Alex Ross has been The New Yorker’s music critic since 1996, and also covers literature, history, and ecology, among other topics. He is the author of “Wagnerism: Art and Politics in the Shadow of Music.”Read MoreBook CurrentsReading for the New Year: Part ThreeRecommendations from New Yorker writers.TakesPatrick Radden Keefe on Truman Capote’s “In Cold Blood”Capote’s journalistic transgressions were serious, but there is no denying the awesome influence of his work.Critic’s NotebookWhy Jackie Robinson Testified Against Paul RobesonA new book presents the baseball legend’s testimony in front of the House Un-American Activities Committee as a critical psychic injury in the annals of Black celebrity.A Critic at LargeThe New York Shooting That Defined an EraOn a mild December day in 1984, a man named Bernie Goetz shot four Black teen-agers on a subway. The incident galvanized the city. Are we still living in its wake?Second ReadThe Brilliance and the Badness of “The Sun Also Rises”Although Ernest Hemingway’s novel makes positive claims about what one should be—brave, admiring of nature and grace—its architecture is held up primarily by hatred.BooksMarx, Palestine, and the Birth of Modern TerrorismA new history charts how Palestinian militants of the nineteen-seventies made common cause with West Germany’s radical left.BooksThe Perennial Predicament of the Artist with an Office JobIn “The Copywriter,” by Daniel Poppick, a poet searches for meaning in the grindset.Annals of TechnologyHow WhatsApp Took Over the Global ConversationThe platform has become a core technology around the world, relied on by governments and extended families alike. What are we all doing there?Open QuestionsIs Good Taste a Trap?The judgments we use to elevate our lives can also hem them in.TakesEmily Nussbaum on Jane Kramer’s “Founding Cadre”Her startling 1970 article, based on months of reporting on radical feminist pioneers, was an outlier for the period—coolly observational but full of emotion.Annals of InquiryAnimals Say Hello, but Do They Say Goodbye?In recent years, researchers have challenged the idea that farewells are uniquely human.Goings OnLouise Bourgeois’s Art Can Still EnthrallAlso: the many disciplines of Sudan Archives, a Max Ophüls retrospective, the facets of upstate cults, and more.NewsBooks & CultureFiction & PoetryHumor & CartoonsMagazineCrosswordVideoPodcasts100th AnniversaryGoings OnManage AccountShop The New YorkerBuy Covers and CartoonsCondé Nast StoreDigital AccessSubscribeNewslettersJigsaw PuzzleRSSSite MapAboutCareersContactF.A.Q.Media KitPressAccessibility HelpUser AgreementPrivacy PolicyYour California Privacy Rights© 2026 Condé Nast. All rights reserved. The New Yorker may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad ChoicesInstagramTiktokThreadsXFacebookLinkedInYouTube')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#installed the langchain package into the current uv environment\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.newyorker.com/magazine/2024/04/22/what-is-noise\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b22bd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "articleSummary(Author='Alex Ross', Title='What Is Noise?', Relevance='This article provides an extensive exploration of the concept of noise, relevant for AI professionals because it addresses noise in the context of data and communication, which are key considerations in developing robust AI systems. Understanding the historical and cultural context of noise can inform AI methodologies for handling data noise and improving signal clarity in information processing.', Summary='Alex Ross explores the multifaceted nature of noise, tracing its linguistic origins and examining its influence on culture, technology, and human perception. Historically associated with nuisance and chaos, noise has evolved to encompass both disruptive and empowering qualities. Ross delves into how noise is culturally perceived, from joyous religious expressions to oppressive urban clamor. He describes the interplay between noise and music, highlighting how personal perceptions of noise differ based on context and control. Noise is also a social and political issue, reflecting disparities in access to quiet spaces and power dynamics in urban settings. Technologically, noise has transformed from a purely acoustic phenomenon to one of data and information, impacting fields like information theory and AI. The article explores how noise influences human creativity, societal behavior, and personal identity, affirming that while often unwelcome, noise is a fundamental part of modern life and technological advancement.', Tone='Informative and Analytical', InputTokens=1000, OutputTokens=241)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ok, now the output is a single long string\n",
    "#try to load the model\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "\n",
    "client = OpenAI(default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1')\n",
    "\n",
    "#based on example in 04_1 ,define what I want from the output?\n",
    "#try a different model that is not gpt-4 :D\n",
    "#define fields\n",
    "relevance_instructions = \"statement, no longer than one paragraph,that explains why is this article relevant for an AI professional in their professional development.\" \n",
    "tone_instructions = \"scientific articles for the general public\"\n",
    "max_tokens = 1000\n",
    "\n",
    "class articleSummary(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions= f\"Summarize the document in the tone of {tone_instructions}. \\\n",
    "    The Relevance field should contain a {relevance_instructions} \\\n",
    "        The Summary field should be a relevant, concise, and succinct summary no longer than {max_tokens}] tokens. Do not add extra information not contained within the original text.\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is the document {docs}\",\n",
    "        },\n",
    "    ],\n",
    "    text_format=articleSummary,\n",
    ")\n",
    "\n",
    "ai_output = response.output_parsed\n",
    "ai_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6680d98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Author\": \"Alex Ross\",\n",
      "  \"Title\": \"What Is Noise?\",\n",
      "  \"Relevance\": \"This article provides an extensive exploration of the concept of noise, relevant for AI professionals because it addresses noise in the context of data and communication, which are key considerations in developing robust AI systems. Understanding the historical and cultural context of noise can inform AI methodologies for handling data noise and improving signal clarity in information processing.\",\n",
      "  \"Summary\": \"Alex Ross explores the multifaceted nature of noise, tracing its linguistic origins and examining its influence on culture, technology, and human perception. Historically associated with nuisance and chaos, noise has evolved to encompass both disruptive and empowering qualities. Ross delves into how noise is culturally perceived, from joyous religious expressions to oppressive urban clamor. He describes the interplay between noise and music, highlighting how personal perceptions of noise differ based on context and control. Noise is also a social and political issue, reflecting disparities in access to quiet spaces and power dynamics in urban settings. Technologically, noise has transformed from a purely acoustic phenomenon to one of data and information, impacting fields like information theory and AI. The article explores how noise influences human creativity, societal behavior, and personal identity, affirming that while often unwelcome, noise is a fundamental part of modern life and technological advancement.\",\n",
      "  \"Tone\": \"Informative and Analytical\",\n",
      "  \"InputTokens\": 7934,\n",
      "  \"OutputTokens\": 271\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#ok, i have the output now, but I would like it to look nice\n",
    "import json\n",
    "#set the actual values for the tokens\n",
    "ai_output.InputTokens = response.usage.input_tokens\n",
    "ai_output.OutputTokens = response.usage.output_tokens\n",
    "print(json.dumps(ai_output.model_dump(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x18384686ba0 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:116\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_async:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\models\\retry_policy.py:659\u001b[39m, in \u001b[36mcreate_retry_decorator.<locals>._decorator.<locals>.attempt\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(coro, per_attempt_timeout)\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio.TimeoutError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\models\\llms\\openai_model.py:221\u001b[39m, in \u001b[36mGPTModel.a_generate\u001b[39m\u001b[34m(self, prompt, schema)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_structured_outputs() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     completion = \u001b[38;5;28;01mawait\u001b[39;00m client.beta.chat.completions.parse(\n\u001b[32m    222\u001b[39m         model=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    223\u001b[39m         messages=[\n\u001b[32m    224\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: content},\n\u001b[32m    225\u001b[39m         ],\n\u001b[32m    226\u001b[39m         response_format=schema,\n\u001b[32m    227\u001b[39m         temperature=\u001b[38;5;28mself\u001b[39m.temperature,\n\u001b[32m    228\u001b[39m         **\u001b[38;5;28mself\u001b[39m.generation_kwargs,\n\u001b[32m    229\u001b[39m     )\n\u001b[32m    230\u001b[39m     structured_output: BaseModel = completion.choices[\n\u001b[32m    231\u001b[39m         \u001b[32m0\u001b[39m\n\u001b[32m    232\u001b[39m     ].message.parsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1670\u001b[39m, in \u001b[36mAsyncCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m   1665\u001b[39m         response_format=response_format,\n\u001b[32m   1666\u001b[39m         chat_completion=raw_completion,\n\u001b[32m   1667\u001b[39m         input_tools=tools,\n\u001b[32m   1668\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1671\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1672\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1673\u001b[39m         {\n\u001b[32m   1674\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   1675\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1676\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   1677\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   1678\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   1679\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   1680\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   1681\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   1682\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   1683\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   1684\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1685\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   1686\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   1687\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1688\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   1689\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   1690\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   1691\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   1692\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   1693\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: _type_to_response_format(response_format),\n\u001b[32m   1694\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   1695\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   1696\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1697\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1698\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   1699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1700\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   1701\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1702\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1703\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   1705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1707\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   1708\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   1709\u001b[39m         },\n\u001b[32m   1710\u001b[39m         completion_create_params.CompletionCreateParams,\n\u001b[32m   1711\u001b[39m     ),\n\u001b[32m   1712\u001b[39m     options=make_request_options(\n\u001b[32m   1713\u001b[39m         extra_headers=extra_headers,\n\u001b[32m   1714\u001b[39m         extra_query=extra_query,\n\u001b[32m   1715\u001b[39m         extra_body=extra_body,\n\u001b[32m   1716\u001b[39m         timeout=timeout,\n\u001b[32m   1717\u001b[39m         post_parser=parser,\n\u001b[32m   1718\u001b[39m     ),\n\u001b[32m   1719\u001b[39m     \u001b[38;5;66;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;00m\n\u001b[32m   1720\u001b[39m     \u001b[38;5;66;03m# in the `parser` function above\u001b[39;00m\n\u001b[32m   1721\u001b[39m     cast_to=cast(Type[ParsedChatCompletion[ResponseFormatT]], ChatCompletion),\n\u001b[32m   1722\u001b[39m     stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1723\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\openai\\_base_client.py:1881\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1878\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1879\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1880\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1881\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\openai\\_base_client.py:1666\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1665\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1666\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'message': 'Limit Exceeded'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRetryError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     24\u001b[39m summarization_assessment = SummarizationMetric(\n\u001b[32m     25\u001b[39m     threshold=\u001b[32m0.5\u001b[39m,\n\u001b[32m     26\u001b[39m     model=model_test,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     ]\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# To run metric as a standalone\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# metric.measure(test_case)\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# print(metric.score, metric.reason)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m summ_result = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdocument_summarization\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msummarization_assessment\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\evaluate.py:228\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(test_cases, metrics, metric_collection, hyperparameters, identifier, async_config, display_config, cache_config, error_config)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m async_config.run_async:\n\u001b[32m    227\u001b[39m     loop = get_or_create_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     test_results = \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma_execute_test_cases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43merror_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdisplay_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplay_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43masync_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43masync_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     test_results = execute_test_cases(\n\u001b[32m    241\u001b[39m         test_cases,\n\u001b[32m    242\u001b[39m         metrics,\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m         cache_config=cache_config,\n\u001b[32m    247\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:678\u001b[39m, in \u001b[36ma_execute_test_cases\u001b[39m\u001b[34m(test_cases, metrics, error_config, display_config, cache_config, async_config, identifier, test_run_manager, _use_bar_indicator, _is_assert_test)\u001b[39m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(async_config.throttle_value)\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    679\u001b[39m         asyncio.gather(*tasks),\n\u001b[32m    680\u001b[39m         timeout=get_gather_timeout(),\n\u001b[32m    681\u001b[39m     )\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio.TimeoutError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    683\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tasks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:581\u001b[39m, in \u001b[36ma_execute_test_cases.<locals>.execute_with_semaphore\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_with_semaphore\u001b[39m(func: Callable, *args, **kwargs):\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _await_with_outer_deadline(\n\u001b[32m    582\u001b[39m             func, *args, timeout=get_per_task_timeout_seconds(), **kwargs\n\u001b[32m    583\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:300\u001b[39m, in \u001b[36m_await_with_outer_deadline\u001b[39m\u001b[34m(obj, timeout, *args, **kwargs)\u001b[39m\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_settings().DEEPEVAL_DISABLE_TIMEOUTS:\n\u001b[32m    298\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(coro, timeout=timeout)\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    302\u001b[39m     reset_outer_deadline(token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:807\u001b[39m, in \u001b[36m_a_execute_llm_test_cases\u001b[39m\u001b[34m(metrics, test_case, test_run_manager, test_results, count, test_run, ignore_errors, skip_on_missing_params, use_cache, show_indicator, _use_bar_indicator, _is_assert_test, progress, pbar_id)\u001b[39m\n\u001b[32m    804\u001b[39m     new_cached_test_case: CachedTestCase = CachedTestCase()\n\u001b[32m    805\u001b[39m     test_start_time = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m measure_metrics_with_indicator(\n\u001b[32m    808\u001b[39m         metrics=metrics,\n\u001b[32m    809\u001b[39m         test_case=test_case,\n\u001b[32m    810\u001b[39m         cached_test_case=cached_test_case,\n\u001b[32m    811\u001b[39m         skip_on_missing_params=skip_on_missing_params,\n\u001b[32m    812\u001b[39m         ignore_errors=ignore_errors,\n\u001b[32m    813\u001b[39m         show_indicator=show_metrics_indicator,\n\u001b[32m    814\u001b[39m         pbar_eval_id=pbar_test_case_id,\n\u001b[32m    815\u001b[39m         progress=progress,\n\u001b[32m    816\u001b[39m     )\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_settings().DEEPEVAL_DISABLE_TIMEOUTS:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\indicator.py:235\u001b[39m, in \u001b[36mmeasure_metrics_with_indicator\u001b[39m\u001b[34m(metrics, test_case, cached_test_case, ignore_errors, skip_on_missing_params, show_indicator, progress, pbar_eval_id, _in_component)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    223\u001b[39m         tasks.append(\n\u001b[32m    224\u001b[39m             safe_a_measure(\n\u001b[32m    225\u001b[39m                 metric,\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m             )\n\u001b[32m    233\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\indicator.py:248\u001b[39m, in \u001b[36msafe_a_measure\u001b[39m\u001b[34m(metric, tc, ignore_errors, skip_on_missing_params, progress, pbar_eval_id, _in_component)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msafe_a_measure\u001b[39m(\n\u001b[32m    239\u001b[39m     metric: Union[BaseMetric, BaseConversationalMetric],\n\u001b[32m    240\u001b[39m     tc: Union[LLMTestCase, LLMTestCase, ConversationalTestCase],\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m     _in_component: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    246\u001b[39m ):\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m metric.a_measure(\n\u001b[32m    249\u001b[39m             tc,\n\u001b[32m    250\u001b[39m             _show_indicator=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    251\u001b[39m             _in_component=_in_component,\n\u001b[32m    252\u001b[39m             _log_metric_to_confident=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    253\u001b[39m         )\n\u001b[32m    254\u001b[39m         update_pbar(progress, pbar_eval_id)\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\summarization\\summarization.py:166\u001b[39m, in \u001b[36mSummarizationMetric.a_measure\u001b[39m\u001b[34m(self, test_case, _show_indicator, _in_component, _log_metric_to_confident)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.evaluation_cost = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.using_native_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m metric_progress_indicator(\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    162\u001b[39m     async_mode=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    163\u001b[39m     _show_indicator=_show_indicator,\n\u001b[32m    164\u001b[39m     _in_component=_in_component,\n\u001b[32m    165\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28mself\u001b[39m.truths, \u001b[38;5;28mself\u001b[39m.claims = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    167\u001b[39m         \u001b[38;5;28mself\u001b[39m._a_generate_truths(test_case.input),\n\u001b[32m    168\u001b[39m         \u001b[38;5;28mself\u001b[39m._a_generate_claims(test_case.actual_output),\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    170\u001b[39m     (\n\u001b[32m    171\u001b[39m         \u001b[38;5;28mself\u001b[39m.coverage_verdicts,\n\u001b[32m    172\u001b[39m         \u001b[38;5;28mself\u001b[39m.alignment_verdicts,\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m         \u001b[38;5;28mself\u001b[39m._a_generate_alignment_verdicts(),\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m     alignment_score = \u001b[38;5;28mself\u001b[39m._calculate_score(ScoreType.ALIGNMENT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\summarization\\summarization.py:481\u001b[39m, in \u001b[36mSummarizationMetric._a_generate_claims\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_a_generate_claims\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    479\u001b[39m     \u001b[38;5;66;03m# Borrow faithfulness template\u001b[39;00m\n\u001b[32m    480\u001b[39m     prompt = FaithfulnessTemplate.generate_claims(actual_output=text)\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m a_generate_with_schema_and_extract(\n\u001b[32m    482\u001b[39m         metric=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    483\u001b[39m         prompt=prompt,\n\u001b[32m    484\u001b[39m         schema_cls=Claims,\n\u001b[32m    485\u001b[39m         extract_schema=\u001b[38;5;28;01mlambda\u001b[39;00m s: s.claims,\n\u001b[32m    486\u001b[39m         extract_json=\u001b[38;5;28;01mlambda\u001b[39;00m data: data[\u001b[33m\"\u001b[39m\u001b[33mclaims\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    487\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\utils.py:452\u001b[39m, in \u001b[36ma_generate_with_schema_and_extract\u001b[39m\u001b[34m(metric, prompt, schema_cls, extract_schema, extract_json)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34ma_generate_with_schema_and_extract\u001b[39m(\n\u001b[32m    444\u001b[39m     metric: Union[BaseMetric, BaseArenaMetric, BaseConversationalMetric],\n\u001b[32m    445\u001b[39m     prompt: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m     extract_json: Callable[[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], ReturnType],\n\u001b[32m    450\u001b[39m ) -> ReturnType:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metric.using_native_model:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m         result, cost = \u001b[38;5;28;01mawait\u001b[39;00m metric.model.a_generate_with_schema(\n\u001b[32m    453\u001b[39m             prompt, schema=schema_cls\n\u001b[32m    454\u001b[39m         )\n\u001b[32m    455\u001b[39m         metric._accrue_cost(cost)\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\models\\base_model.py:118\u001b[39m, in \u001b[36mDeepEvalBaseLLM.a_generate_with_schema\u001b[39m\u001b[34m(self, schema, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.a_generate(*args, schema=schema, **kwargs)\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    120\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:193\u001b[39m, in \u001b[36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    192\u001b[39m async_wrapped.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:112\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m is_async = _utils.is_coroutine_callable(fn)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:157\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    155\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\_utils.py:111\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\__init__.py:414\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc.reraise()\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[31mRetryError\u001b[39m: RetryError[<Future at 0x18384686ba0 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.models import GPTModel\n",
    "\n",
    "\n",
    "#1. Summarization metric\n",
    "#using the documentation as an example\n",
    "\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "\n",
    "model_test = GPTModel(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key='any value',\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1',\n",
    ")\n",
    "\n",
    "document_summarization = LLMTestCase(input=document_text, actual_output=ai_output.Summary)\n",
    "\n",
    "summarization_assessment = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=model_test,\n",
    "    assessment_questions=[\n",
    "        \"Is the summary factual and faithful to the original source?\",\n",
    "        f\"Is the tone of the summary consistent with the user-defined tone of {tone_instructions}?\",\n",
    "        \"Does the summary accurate capture the main statements of the original source?\"\n",
    "        \"Is the summary free of spelling and grammatical errors?\",\n",
    "        \"Are all claims in the summary directly supported by the source text?\"\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# To run metric as a standalone\n",
    "# metric.measure(test_case)\n",
    "# print(metric.score, metric.reason)\n",
    "\n",
    "summ_result = evaluate(test_cases=[document_summarization], metrics=[summarization_assessment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1c3fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try the G-eval method?\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "#from the docs:\n",
    "#define model again from using the gateway key\n",
    "model = GPTModel(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    # api_key='any value',\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1',\n",
    ")\n",
    "\n",
    "clarity = GEval(\n",
    "    name=\"clarity_assessment\",\n",
    "    evaluation_steps=[\n",
    "        \"Make sure that the summary is clear, concise, and easy to read for someone who would read a scientific press release?\",\n",
    "        \"Check if there are any terms that need to be defined (e.g., jargon).\",\n",
    "        \"Make sure that the logic flows clearly from each sentence to the next.\",\n",
    "        \"Determine if the sentences are structured in a way that makes it easy to understand.\",\n",
    "        \"Is there redundant or extra text that is not needed to understand the summary?\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "professionalism = GEval(\n",
    "    name=\"professionalism_assessment\",\n",
    "    evaluation_steps=[\n",
    "        \"Is the tone of the output professional and objective?\",\n",
    "        \"Are there any slang terms or common names of concepts that could be replaced with more professional terminology?\",\n",
    "        \"Make sure that the style of the output is consistent with professional writing standards.\",\n",
    "        \"Determine if the sentence structure follows that of professional scientific writing.\",\n",
    "        \"Ensure that the overall structure of the summary is professional.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "safety = GEval(\n",
    "    name=\"safety_assessment\",\n",
    "    evaluation_steps=[\n",
    "        \"Ensure that the output does not contain information not directly available in the body of the document provided.\",\n",
    "        \"Identify if there are any phrases that might be considered suggestive or inappropriate from any perspective.\",\n",
    "        \"Determine if there are any metadata that contains private information or other identifying factors that are not public.\",\n",
    "        \"Make sure that the output does not contain any information that may be dangerous to the user, or pose a safety risk to anyone.\",\n",
    "        \"Verify that no harmful biases in relation to gender, socioeconomics, religion, or race is present in the output.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">clarity_assessment </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mclarity_assessment \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x1838454b140 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:116\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_async:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\models\\retry_policy.py:659\u001b[39m, in \u001b[36mcreate_retry_decorator.<locals>._decorator.<locals>.attempt\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(coro, per_attempt_timeout)\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio.TimeoutError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\models\\llms\\openai_model.py:340\u001b[39m, in \u001b[36mGPTModel.a_generate_raw_response\u001b[39m\u001b[34m(self, prompt, top_logprobs)\u001b[39m\n\u001b[32m    339\u001b[39m     content = [{\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: prompt}]\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m completion = \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(\n\u001b[32m    341\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    342\u001b[39m     messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: content}],\n\u001b[32m    343\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m.temperature,\n\u001b[32m    344\u001b[39m     logprobs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    345\u001b[39m     top_logprobs=top_logprobs,\n\u001b[32m    346\u001b[39m     **\u001b[38;5;28mself\u001b[39m.generation_kwargs,\n\u001b[32m    347\u001b[39m )\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# Cost calculation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2678\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2677\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2679\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2680\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2681\u001b[39m         {\n\u001b[32m   2682\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2683\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2684\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2685\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2686\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2687\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2688\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2689\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2690\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2691\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2692\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2693\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2694\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2695\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2696\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2697\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2698\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   2700\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2701\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2702\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2703\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2707\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2708\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2709\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2710\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2711\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2712\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2713\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2714\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2715\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2716\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2717\u001b[39m         },\n\u001b[32m   2718\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2719\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2720\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2721\u001b[39m     ),\n\u001b[32m   2722\u001b[39m     options=make_request_options(\n\u001b[32m   2723\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2724\u001b[39m     ),\n\u001b[32m   2725\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2726\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2727\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2728\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\openai\\_base_client.py:1881\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1878\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1879\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1880\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1881\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\openai\\_base_client.py:1666\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1665\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1666\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'message': 'Limit Exceeded'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRetryError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m test_case = LLMTestCase(\n\u001b[32m      2\u001b[39m     \u001b[38;5;28minput\u001b[39m=document_text,\n\u001b[32m      3\u001b[39m     actual_output=response.output_text\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclarity\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\evaluate.py:228\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(test_cases, metrics, metric_collection, hyperparameters, identifier, async_config, display_config, cache_config, error_config)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m async_config.run_async:\n\u001b[32m    227\u001b[39m     loop = get_or_create_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     test_results = \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma_execute_test_cases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43merror_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdisplay_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplay_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43masync_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43masync_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     test_results = execute_test_cases(\n\u001b[32m    241\u001b[39m         test_cases,\n\u001b[32m    242\u001b[39m         metrics,\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m         cache_config=cache_config,\n\u001b[32m    247\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:678\u001b[39m, in \u001b[36ma_execute_test_cases\u001b[39m\u001b[34m(test_cases, metrics, error_config, display_config, cache_config, async_config, identifier, test_run_manager, _use_bar_indicator, _is_assert_test)\u001b[39m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(async_config.throttle_value)\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    679\u001b[39m         asyncio.gather(*tasks),\n\u001b[32m    680\u001b[39m         timeout=get_gather_timeout(),\n\u001b[32m    681\u001b[39m     )\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio.TimeoutError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    683\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tasks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:581\u001b[39m, in \u001b[36ma_execute_test_cases.<locals>.execute_with_semaphore\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_with_semaphore\u001b[39m(func: Callable, *args, **kwargs):\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _await_with_outer_deadline(\n\u001b[32m    582\u001b[39m             func, *args, timeout=get_per_task_timeout_seconds(), **kwargs\n\u001b[32m    583\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:300\u001b[39m, in \u001b[36m_await_with_outer_deadline\u001b[39m\u001b[34m(obj, timeout, *args, **kwargs)\u001b[39m\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_settings().DEEPEVAL_DISABLE_TIMEOUTS:\n\u001b[32m    298\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(coro, timeout=timeout)\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    302\u001b[39m     reset_outer_deadline(token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\evaluate\\execute.py:807\u001b[39m, in \u001b[36m_a_execute_llm_test_cases\u001b[39m\u001b[34m(metrics, test_case, test_run_manager, test_results, count, test_run, ignore_errors, skip_on_missing_params, use_cache, show_indicator, _use_bar_indicator, _is_assert_test, progress, pbar_id)\u001b[39m\n\u001b[32m    804\u001b[39m     new_cached_test_case: CachedTestCase = CachedTestCase()\n\u001b[32m    805\u001b[39m     test_start_time = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m measure_metrics_with_indicator(\n\u001b[32m    808\u001b[39m         metrics=metrics,\n\u001b[32m    809\u001b[39m         test_case=test_case,\n\u001b[32m    810\u001b[39m         cached_test_case=cached_test_case,\n\u001b[32m    811\u001b[39m         skip_on_missing_params=skip_on_missing_params,\n\u001b[32m    812\u001b[39m         ignore_errors=ignore_errors,\n\u001b[32m    813\u001b[39m         show_indicator=show_metrics_indicator,\n\u001b[32m    814\u001b[39m         pbar_eval_id=pbar_test_case_id,\n\u001b[32m    815\u001b[39m         progress=progress,\n\u001b[32m    816\u001b[39m     )\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_settings().DEEPEVAL_DISABLE_TIMEOUTS:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\indicator.py:235\u001b[39m, in \u001b[36mmeasure_metrics_with_indicator\u001b[39m\u001b[34m(metrics, test_case, cached_test_case, ignore_errors, skip_on_missing_params, show_indicator, progress, pbar_eval_id, _in_component)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    223\u001b[39m         tasks.append(\n\u001b[32m    224\u001b[39m             safe_a_measure(\n\u001b[32m    225\u001b[39m                 metric,\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m             )\n\u001b[32m    233\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\indicator.py:248\u001b[39m, in \u001b[36msafe_a_measure\u001b[39m\u001b[34m(metric, tc, ignore_errors, skip_on_missing_params, progress, pbar_eval_id, _in_component)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msafe_a_measure\u001b[39m(\n\u001b[32m    239\u001b[39m     metric: Union[BaseMetric, BaseConversationalMetric],\n\u001b[32m    240\u001b[39m     tc: Union[LLMTestCase, LLMTestCase, ConversationalTestCase],\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m     _in_component: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    246\u001b[39m ):\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m metric.a_measure(\n\u001b[32m    249\u001b[39m             tc,\n\u001b[32m    250\u001b[39m             _show_indicator=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    251\u001b[39m             _in_component=_in_component,\n\u001b[32m    252\u001b[39m             _log_metric_to_confident=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    253\u001b[39m         )\n\u001b[32m    254\u001b[39m         update_pbar(progress, pbar_eval_id)\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\g_eval\\g_eval.py:193\u001b[39m, in \u001b[36mGEval.a_measure\u001b[39m\u001b[34m(self, test_case, _show_indicator, _in_component, _log_metric_to_confident, _additional_context)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m metric_progress_indicator(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     async_mode=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    187\u001b[39m     _show_indicator=_show_indicator,\n\u001b[32m    188\u001b[39m     _in_component=_in_component,\n\u001b[32m    189\u001b[39m ):\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m.evaluation_steps: List[\u001b[38;5;28mstr\u001b[39m] = (\n\u001b[32m    191\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._a_generate_evaluation_steps(multimodal)\n\u001b[32m    192\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     g_score, reason = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._a_evaluate(\n\u001b[32m    194\u001b[39m         test_case,\n\u001b[32m    195\u001b[39m         _additional_context=_additional_context,\n\u001b[32m    196\u001b[39m         multimodal=multimodal,\n\u001b[32m    197\u001b[39m     )\n\u001b[32m    198\u001b[39m     \u001b[38;5;28mself\u001b[39m.score = (\n\u001b[32m    199\u001b[39m         (\u001b[38;5;28mfloat\u001b[39m(g_score) - \u001b[38;5;28mself\u001b[39m.score_range[\u001b[32m0\u001b[39m]) / \u001b[38;5;28mself\u001b[39m.score_range_span\n\u001b[32m    200\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.strict_mode\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(g_score)\n\u001b[32m    202\u001b[39m     )\n\u001b[32m    203\u001b[39m     \u001b[38;5;28mself\u001b[39m.success = \u001b[38;5;28mself\u001b[39m.score >= \u001b[38;5;28mself\u001b[39m.threshold\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\deepeval\\metrics\\g_eval\\g_eval.py:304\u001b[39m, in \u001b[36mGEval._a_evaluate\u001b[39m\u001b[34m(self, test_case, multimodal, _additional_context)\u001b[39m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mlog_probs unsupported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;66;03m# Don't have to check for using native model\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[38;5;66;03m# since generate raw response only exist for deepeval's native model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m res, cost = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.a_generate_raw_response(\n\u001b[32m    305\u001b[39m     prompt, top_logprobs=\u001b[38;5;28mself\u001b[39m.top_logprobs\n\u001b[32m    306\u001b[39m )\n\u001b[32m    308\u001b[39m \u001b[38;5;28mself\u001b[39m._accrue_cost(cost)\n\u001b[32m    310\u001b[39m data = trimAndLoadJson(res.choices[\u001b[32m0\u001b[39m].message.content, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:193\u001b[39m, in \u001b[36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    192\u001b[39m async_wrapped.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:112\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m is_async = _utils.is_coroutine_callable(fn)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:157\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    155\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\_utils.py:111\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qqjes\\Documents\\GitHub\\deploying-ai\\ai_env\\Lib\\site-packages\\tenacity\\__init__.py:414\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc.reraise()\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[31mRetryError\u001b[39m: RetryError[<Future at 0x1838454b140 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "test_case = LLMTestCase(\n",
    "    input=document_text,\n",
    "    actual_output=response.output_text\n",
    ")\n",
    "\n",
    "clarity_test = evaluate(test_cases=[test_case], metrics=[clarity])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a6744",
   "metadata": {},
   "source": [
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a631e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SummarizationScore': None, 'SummarizationReason': None, 'ClarityScore': None, 'ClarityReason': None, 'ProfessionalismScore': None, 'ProfessionalismReason': None, 'SafetyScore': None, 'SafetyReason': None}\n"
     ]
    }
   ],
   "source": [
    "#use the giant output evaluation and separate them\n",
    "evaluation_results = {\n",
    "\"SummarizationScore\":summarization_assessment.score,\n",
    "\"SummarizationReason\":summarization_assessment.reason,\n",
    "\"ClarityScore\":clarity.score,\n",
    "\"ClarityReason\":clarity.reason,\n",
    "\"ProfessionalismScore\":professionalism.score,\n",
    "\"ProfessionalismReason\":professionalism.reason,\n",
    "\"SafetyScore\":safety.score,\n",
    "\"SafetyReason\":safety.reason\n",
    "}\n",
    "\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
